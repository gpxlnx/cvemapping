# poc/load_vulnerable_model.py
import mlflow

# The URI of your MLflow tracking server
MLFLOW_TRACKING_URI = "http://127.0.0.1:5000"
REGISTERED_MODEL_NAME = "rce-payload-model"
MODEL_VERSION = 1 # We are loading the version the attacker just created

# --- Main script logic ---
if __name__ == "__main__":
    print(f"[*] Connecting to MLflow server at {MLFLOW_TRACKING_URI}")
    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)

    # Construct the URI to load the specific model version from the registry
    model_uri = f"models:/{REGISTERED_MODEL_NAME}/{MODEL_VERSION}"
    
    print(f"[*] VICTIM: Attempting to load model from URI: {model_uri}")
    print("[*] The payload will execute on the next line if the model is malicious...")
    
    try:
        # ⚠️ THIS IS THE DANGEROUS STEP ⚠️
        # When load_model is called, it uses pickle to deserialize the model file.
        # This triggers the __reduce__ method in the attacker's code.
        loaded_model = mlflow.pyfunc.load_model(model_uri)
        
        print("\n[*] Model loaded successfully into memory.")
        print("[*] Check your terminal output and directory for the payload's effects.")
        
    except Exception as e:
        print(f"\n[!] An error occurred: {e}")
