# CVE-2025-54794-Hijacking-Claude-AI-with-a-Prompt-Injection-The-Jailbreak-That-Talked-Back
A high-severity prompt injection flaw in Claude AI proves that even the smartest language models can be turned into weapons â€” all with a few lines of code.
